{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import openai\n",
    "import tiktoken\n",
    "import dotenv\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure OpenAI API\n",
    "# os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_TYPE = os.environ.get(\"AZURE_OPENAI_API_TYPE\")\n",
    "AZURE_OPENAI_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_API_VERSION = os.environ.get(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_CHAT_MODEL = os.environ.get(\"AZURE_OPENAI_CHAT_MODEL\")\n",
    "AZURE_OPENAI_EMBEDDING_MODEL = os.environ.get(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    "openai.api_type = AZURE_OPENAI_API_TYPE\n",
    "openai.api_version = AZURE_OPENAI_API_VERSION\n",
    "openai.api_base = AZURE_OPENAI_ENDPOINT\n",
    "openai.api_key = AZURE_OPENAI_API_KEY\n",
    "\n",
    "print(AZURE_OPENAI_ENDPOINT)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the location of the PDF file.\n",
    "pdfReader = PdfReader('../../Sample-Data/LLM-AI-Agents.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the text from the PDF file.\n",
    "raw_text = ''\n",
    "for i, page in enumerate(pdfReader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 1000 characters of the text.\n",
    "raw_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into chunks of 1000 characters with 200 characters overlap.\n",
    "text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "pdfTexts = text_splitter.split_text(raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show how many chunks of text are generated.\n",
    "len(pdfTexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the text chunks to the Embedding Model from Azure OpenAI API to generate embeddings.\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_base= AZURE_OPENAI_ENDPOINT,\n",
    "    openai_api_type=AZURE_OPENAI_API_TYPE,\n",
    "    deployment=AZURE_OPENAI_EMBEDDING_MODEL,\n",
    "    openai_api_key=AZURE_OPENAI_API_KEY,\n",
    "    chunk_size=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use FAISS to index the embeddings. This will allow us to perform a similarity search on the texts using the embeddings.\n",
    "# https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/faiss.html\n",
    "pdfDocSearch = FAISS.from_texts(pdfTexts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=None callbacks=None callback_manager=None verbose=False tags=None metadata=None input_key='input_documents' output_key='output_text' llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=ChatPromptTemplate(input_variables=['context', 'question'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], output_parser=None, partial_variables={}, template=\"Use the following pieces of context to answer the users question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\", template_format='f-string', validate_template=True), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='{question}', template_format='f-string', validate_template=True), additional_kwargs={})]), llm=AzureChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-35-turbo', temperature=0.7, model_kwargs={}, openai_api_key='2b654ad2f4bd41638f6b4631d5d09047', openai_api_base='https://apim-dev-eastus-spotgenai.azure-api.net/Spot-Connect/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None, deployment_name='gpt-35-turbo', model_version='', openai_api_type='azure', openai_api_version='2023-05-15'), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}) document_prompt=PromptTemplate(input_variables=['page_content'], output_parser=None, partial_variables={}, template='{page_content}', template_format='f-string', validate_template=True) document_variable_name='context' document_separator='\\n\\n'\n"
     ]
    }
   ],
   "source": [
    "# Create a Question Answering chain using the embeddings and the similarity search.\n",
    "# https://docs.langchain.com/docs/components/chains/index_related_chains\n",
    "# LangChain Documents in Memory - https://python.langchain.com/docs/use_cases/question_answering/how_to/question_answering#the-stuff-chain\n",
    "chain = load_qa_chain(AzureChatOpenAI(openai_api_key=AZURE_OPENAI_API_KEY, deployment_name=AZURE_OPENAI_CHAT_MODEL, openai_api_base=AZURE_OPENAI_ENDPOINT, model_name=AZURE_OPENAI_CHAT_MODEL, openai_api_version=AZURE_OPENAI_API_VERSION), chain_type=\"stuff\")\n",
    "\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The key summary of this book is that AI agents should be able to summarize the interaction history and provide a concise and easy-to-understand answer for users. Techniques such as chain-of-thought (CoT) and vector databases can be used to achieve this. The book also discusses the design of AI agents, with a focus on task planning and tool usage as the core competencies. However, there are weaknesses identified in LLM-based agents, particularly in understanding output formats. Overall, the book aims to enhance the abilities of AI agents in task planning and tool usage.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform first sample of question answering.\n",
    "inquiry = \"Please tell me the key summary of this book.\"\n",
    "docs = pdfDocSearch.similarity_search(inquiry)\n",
    "chain.run(input_documents=docs, question=inquiry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
